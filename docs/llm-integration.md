# LLMçµ±åˆè¨­è¨ˆ

## ğŸ¤– æ¦‚è¦

OpenAI GPT-5-miniã‚’ä½¿ç”¨ã—ã¦ã€å—é¨“è€…ã®è§£ç­”å†…å®¹ã¨è¡Œå‹•ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æã—ã€ä¸æ­£ãƒªã‚¹ã‚¯ã‚’è©•ä¾¡ã—ã¾ã™ã€‚

---

## ğŸ¯ LLMã®å½¹å‰²

| åˆ†æé …ç›® | ç›®çš„ | å‡ºåŠ› |
|:---|:---|:---|
| **æ©Ÿæ¢°ç¿»è¨³æ¤œå‡º** | DeepL/Googleç¿»è¨³ã®ä½¿ç”¨ã‚’æ¤œå‡º | é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢ï¼ˆ0-100%ï¼‰ |
| **æ–‡ä½“åˆ†æ** | è§£ç­”ã®æµæš¢ã•ã¨å•é¡Œé›£æ˜“åº¦ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ | ä¸è‡ªç„¶åº¦ã‚¹ã‚³ã‚¢ |
| **è¡Œå‹•ãƒ‘ã‚¿ãƒ¼ãƒ³è©•ä¾¡** | è¡Œå‹•ãƒ­ã‚°ã‹ã‚‰ä¸æ­£ã®å¯èƒ½æ€§ã‚’åˆ¤æ–­ | ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢ï¼ˆ0-100%ï¼‰ |
| **ç·åˆè©•ä¾¡** | ä¸Šè¨˜ã‚’çµ±åˆã—ã¦æœ€çµ‚åˆ¤æ–­ | ç†ç”±ä»˜ãã‚¹ã‚³ã‚¢ |

---

## ğŸ“ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­è¨ˆ

### 1. ãƒ¡ã‚¤ãƒ³ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ

```typescript
// lib/llm.ts

const FRAUD_DETECTION_PROMPT = `
ã‚ãªãŸã¯è‹±èªãƒ†ã‚¹ãƒˆã®ä¸æ­£æ¤œå‡ºAIã§ã™ã€‚
å—é¨“è€…ã®è§£ç­”ã¨è¡Œå‹•ãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰ã€ä¸æ­£è¡Œç‚ºã®å¯èƒ½æ€§ã‚’è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚

## è©•ä¾¡å¯¾è±¡ãƒ‡ãƒ¼ã‚¿

### å•é¡Œæ–‡
{questionText}

### å•é¡Œã®é›£æ˜“åº¦
{difficulty} (easy/medium/hard)

### å—é¨“è€…ã®è§£ç­”
{userAnswer}

### è¡Œå‹•ãƒ­ã‚°
- ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦åˆ‡ã‚Šæ›¿ãˆå›æ•°: {blurCount}å›
- å„é›¢è„±æ™‚é–“: {blurDurations}ç§’
- å•é¡Œæ–‡ã®ã‚³ãƒ”ãƒ¼å›æ•°: {copyCount}å›
- ã‚³ãƒ”ãƒ¼ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ: {copiedTexts}
- ãƒšãƒ¼ã‚¹ãƒˆå›æ•°: {pasteCount}å›
- è§£ç­”æ™‚é–“: {answerTime}ç§’
- ãƒã‚¦ã‚¹åœæ­¢æ™‚é–“: {mouseInactiveTime}ç§’
- ã‚¿ã‚¤ãƒ”ãƒ³ã‚°é€Ÿåº¦: {typingSpeed}æ–‡å­—/ç§’

## è©•ä¾¡åŸºæº–

### 1. æ©Ÿæ¢°ç¿»è¨³ã®æ¤œå‡º
ä»¥ä¸‹ã®ç‰¹å¾´ãŒã‚ã‚‹å ´åˆã€æ©Ÿæ¢°ç¿»è¨³ã®å¯èƒ½æ€§ãŒé«˜ã„ï¼š
- DeepLç‰¹æœ‰ã®è¡¨ç¾ï¼ˆä¾‹: "ã€œã™ã‚‹ã“ã¨ãŒã§ãã¾ã™"ã®å¤šç”¨ï¼‰
- Googleç¿»è¨³ç‰¹æœ‰ã®ä¸è‡ªç„¶ãªèªé †
- æ–‡æ³•çš„ã«ã¯æ­£ã—ã„ãŒã€ãƒã‚¤ãƒ†ã‚£ãƒ–ãŒä½¿ã‚ãªã„è¡¨ç¾
- å•é¡Œæ–‡ã®é›£æ˜“åº¦ã«å¯¾ã—ã¦éåº¦ã«æµæš¢

### 2. ä¸æ­£è¡Œå‹•ãƒ‘ã‚¿ãƒ¼ãƒ³
- ã‚³ãƒ”ãƒ¼ç›´å¾Œã®ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦åˆ‡ã‚Šæ›¿ãˆï¼ˆç¿»è¨³ã‚µã‚¤ãƒˆã®ä½¿ç”¨å¯èƒ½æ€§ï¼‰
- é•·æ™‚é–“ã®ãƒã‚¦ã‚¹åœæ­¢ + é«˜å“è³ªãªè§£ç­”ï¼ˆä»–äººãŒä»£è¡Œã®å¯èƒ½æ€§ï¼‰
- ç•°å¸¸ã«é€Ÿã„ã‚¿ã‚¤ãƒ”ãƒ³ã‚°ï¼ˆã‚³ãƒ”ãƒšã®å¯èƒ½æ€§ï¼‰
- é »ç¹ãªãƒšãƒ¼ã‚¹ãƒˆæ“ä½œ

### 3. è§£ç­”ã®ä¸€è²«æ€§
- å•é¡Œã®é›£æ˜“åº¦ã¨è§£ç­”ã®è³ªã®ä¸ä¸€è‡´
- å—é¨“è€…ã®ä»–ã®è§£ç­”ã¨ã®æ–‡ä½“ã®é•ã„

## å‡ºåŠ›å½¢å¼

ä»¥ä¸‹ã®JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š

{
  "riskScore": 0-100ã®æ•°å€¤,
  "translationLikelihood": 0-100ã®æ•°å€¤,
  "reasons": [
    "ç†ç”±1",
    "ç†ç”±2",
    "ç†ç”±3"
  ],
  "suspiciousPatterns": [
    "æ¤œå‡ºã•ã‚ŒãŸãƒ‘ã‚¿ãƒ¼ãƒ³å"
  ],
  "answerQuality": 0-1ã®æ•°å€¤,
  "recommendation": "æ•™å¸«ã¸ã®æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³"
}

## é‡è¦ãªæ³¨æ„äº‹é …
- èª¤æ¤œçŸ¥ã‚’é¿ã‘ã‚‹ãŸã‚ã€ç¢ºå®Ÿãªè¨¼æ‹ ãŒã‚ã‚‹å ´åˆã®ã¿é«˜ã‚¹ã‚³ã‚¢ã‚’ä»˜ã‘ã‚‹
- ç–‘ã‚ã—ã„ãŒç¢ºè¨¼ãŒãªã„å ´åˆã¯ä¸­ç¨‹åº¦ã®ã‚¹ã‚³ã‚¢ã¨ã—ã€ãã®æ—¨ã‚’ç†ç”±ã«è¨˜è¼‰
- æ­£å¸¸ãªè¡Œå‹•ãƒ‘ã‚¿ãƒ¼ãƒ³ã®å ´åˆã¯ä½ã‚¹ã‚³ã‚¢ã‚’ä»˜ã‘ã€ãã®æ ¹æ‹ ã‚’ç¤ºã™
`;
```

---

## ğŸ”§ å®Ÿè£…

### lib/llm.ts

```typescript
import OpenAI from 'openai';
import type { BehaviorLog } from '@/types';

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

const MODEL = process.env.OPENAI_MODEL || 'gpt-5-mini';

export interface LLMAnalysisInput {
  questionText: string;
  questionDifficulty: string;
  userAnswer: string;
  behaviorLogs: BehaviorLog;
  answerTime: number;
}

export interface LLMAnalysisResult {
  riskScore: number;
  translationLikelihood: number;
  reasons: string[];
  suspiciousPatterns: string[];
  answerQuality: number;
  recommendation: string;
}

export async function analyzeBehavior(
  input: LLMAnalysisInput
): Promise<LLMAnalysisResult> {
  try {
    const prompt = buildPrompt(input);
    
    const response = await openai.chat.completions.create({
      model: MODEL,
      messages: [
        {
          role: 'system',
          content: 'ä½ ã¯è‹±èªãƒ†ã‚¹ãƒˆã®ä¸æ­£æ¤œå‡ºã‚’å°‚é–€ã¨ã™ã‚‹AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚',
        },
        {
          role: 'user',
          content: prompt,
        },
      ],
      temperature: 0.3, // ä½ã‚ã«è¨­å®šã—ã¦ä¸€è²«æ€§ã‚’ç¢ºä¿
      response_format: { type: 'json_object' },
    });
    
    const content = response.choices[0].message.content;
    if (!content) {
      throw new Error('Empty response from OpenAI');
    }
    
    const result = JSON.parse(content) as LLMAnalysisResult;
    
    // ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
    validateResult(result);
    
    return result;
  } catch (error) {
    console.error('LLM analysis error:', error);
    
    // ã‚¨ãƒ©ãƒ¼æ™‚ã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    return {
      riskScore: 50,
      translationLikelihood: 0,
      reasons: ['LLMåˆ†æã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ'],
      suspiciousPatterns: [],
      answerQuality: 0.5,
      recommendation: 'æ‰‹å‹•ã§ç¢ºèªã—ã¦ãã ã•ã„',
    };
  }
}

function buildPrompt(input: LLMAnalysisInput): string {
  const {
    questionText,
    questionDifficulty,
    userAnswer,
    behaviorLogs,
    answerTime,
  } = input;
  
  return `
ã‚ãªãŸã¯è‹±èªãƒ†ã‚¹ãƒˆã®ä¸æ­£æ¤œå‡ºAIã§ã™ã€‚
å—é¨“è€…ã®è§£ç­”ã¨è¡Œå‹•ãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰ã€ä¸æ­£è¡Œç‚ºã®å¯èƒ½æ€§ã‚’è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚

## è©•ä¾¡å¯¾è±¡ãƒ‡ãƒ¼ã‚¿

### å•é¡Œæ–‡
${questionText}

### å•é¡Œã®é›£æ˜“åº¦
${questionDifficulty}

### å—é¨“è€…ã®è§£ç­”
${userAnswer}

### è¡Œå‹•ãƒ­ã‚°
- ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦åˆ‡ã‚Šæ›¿ãˆå›æ•°: ${behaviorLogs.blurCount}å›
- å„é›¢è„±æ™‚é–“: ${behaviorLogs.blurDurations.join(', ')}ãƒŸãƒªç§’
- å•é¡Œæ–‡ã®ã‚³ãƒ”ãƒ¼å›æ•°: ${behaviorLogs.copyCount}å›
- ã‚³ãƒ”ãƒ¼ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ: ${behaviorLogs.copiedTexts.join(', ')}
- ãƒšãƒ¼ã‚¹ãƒˆå›æ•°: ${behaviorLogs.pasteCount}å›
- è§£ç­”æ™‚é–“: ${answerTime}ç§’
- ãƒã‚¦ã‚¹åœæ­¢æ™‚é–“: ${Math.floor(behaviorLogs.mouseInactiveTime / 1000)}ç§’
- ã‚¿ã‚¤ãƒ”ãƒ³ã‚°é€Ÿåº¦: ${behaviorLogs.typingSpeed.toFixed(1)}æ–‡å­—/ç§’

## è©•ä¾¡åŸºæº–

### 1. æ©Ÿæ¢°ç¿»è¨³ã®æ¤œå‡º
ä»¥ä¸‹ã®ç‰¹å¾´ãŒã‚ã‚‹å ´åˆã€æ©Ÿæ¢°ç¿»è¨³ã®å¯èƒ½æ€§ãŒé«˜ã„ï¼š
- DeepLç‰¹æœ‰ã®è¡¨ç¾ï¼ˆä¾‹: "ã€œã™ã‚‹ã“ã¨ãŒã§ãã¾ã™"ã®å¤šç”¨ï¼‰
- Googleç¿»è¨³ç‰¹æœ‰ã®ä¸è‡ªç„¶ãªèªé †
- æ–‡æ³•çš„ã«ã¯æ­£ã—ã„ãŒã€ãƒã‚¤ãƒ†ã‚£ãƒ–ãŒä½¿ã‚ãªã„è¡¨ç¾
- å•é¡Œæ–‡ã®é›£æ˜“åº¦ã«å¯¾ã—ã¦éåº¦ã«æµæš¢

### 2. ä¸æ­£è¡Œå‹•ãƒ‘ã‚¿ãƒ¼ãƒ³
- ã‚³ãƒ”ãƒ¼ç›´å¾Œã®ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦åˆ‡ã‚Šæ›¿ãˆï¼ˆç¿»è¨³ã‚µã‚¤ãƒˆã®ä½¿ç”¨å¯èƒ½æ€§ï¼‰
- é•·æ™‚é–“ã®ãƒã‚¦ã‚¹åœæ­¢ + é«˜å“è³ªãªè§£ç­”ï¼ˆä»–äººãŒä»£è¡Œã®å¯èƒ½æ€§ï¼‰
- ç•°å¸¸ã«é€Ÿã„ã‚¿ã‚¤ãƒ”ãƒ³ã‚°ï¼ˆã‚³ãƒ”ãƒšã®å¯èƒ½æ€§ï¼‰
- é »ç¹ãªãƒšãƒ¼ã‚¹ãƒˆæ“ä½œ

### 3. è§£ç­”ã®ä¸€è²«æ€§
- å•é¡Œã®é›£æ˜“åº¦ã¨è§£ç­”ã®è³ªã®ä¸ä¸€è‡´

## å‡ºåŠ›å½¢å¼

ä»¥ä¸‹ã®JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š

{
  "riskScore": 0-100ã®æ•°å€¤,
  "translationLikelihood": 0-100ã®æ•°å€¤,
  "reasons": ["ç†ç”±1", "ç†ç”±2"],
  "suspiciousPatterns": ["ãƒ‘ã‚¿ãƒ¼ãƒ³å"],
  "answerQuality": 0-1ã®æ•°å€¤,
  "recommendation": "æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³"
}
`.trim();
}

function validateResult(result: any): void {
  if (typeof result.riskScore !== 'number' || 
      result.riskScore < 0 || 
      result.riskScore > 100) {
    throw new Error('Invalid riskScore');
  }
  
  if (!Array.isArray(result.reasons)) {
    throw new Error('Invalid reasons');
  }
  
  if (!Array.isArray(result.suspiciousPatterns)) {
    throw new Error('Invalid suspiciousPatterns');
  }
}
```

---

## ğŸ§ª æ©Ÿæ¢°ç¿»è¨³æ¤œå‡ºã®ä»•çµ„ã¿

### DeepLç‰¹æœ‰ã®ãƒ‘ã‚¿ãƒ¼ãƒ³

| ãƒ‘ã‚¿ãƒ¼ãƒ³ | ä¾‹ |
|:---|:---|
| ä¸å¯§ã™ãã‚‹è¡¨ç¾ | "ã€œã™ã‚‹ã“ã¨ãŒã§ãã¾ã™" |
| å—å‹•æ…‹ã®å¤šç”¨ | "It is considered that..." |
| å†—é•·ãªè¡¨ç¾ | "in order to" ã®é »ç¹ãªä½¿ç”¨ |

### Googleç¿»è¨³ç‰¹æœ‰ã®ãƒ‘ã‚¿ãƒ¼ãƒ³

| ãƒ‘ã‚¿ãƒ¼ãƒ³ | ä¾‹ |
|:---|:---|
| ç›´è¨³çš„ãªèªé † | "very important problem" |
| ä¸è‡ªç„¶ãªå† è© | "a" ã¨ "the" ã®èª¤ç”¨ |
| æ©Ÿæ¢°çš„ãªæ¥ç¶šè© | "However" ã§å§‹ã¾ã‚‹æ–‡ã®é€£ç¶š |

### LLMã«ã‚ˆã‚‹æ¤œå‡ºç²¾åº¦

```typescript
// å®Ÿé¨“çµæœï¼ˆæƒ³å®šï¼‰
{
  "DeepLç¿»è¨³": {
    "æ¤œå‡ºç‡": "85%",
    "èª¤æ¤œçŸ¥ç‡": "10%"
  },
  "Googleç¿»è¨³": {
    "æ¤œå‡ºç‡": "80%",
    "èª¤æ¤œçŸ¥ç‡": "12%"
  },
  "æ‰‹æ›¸ãï¼ˆãƒã‚¤ãƒ†ã‚£ãƒ–ï¼‰": {
    "èª¤æ¤œçŸ¥ç‡": "5%"
  }
}
```

---

## ğŸ“Š ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢çµ±åˆ

### lib/analyzer.ts

```typescript
import type { BehaviorLog } from '@/types';
import type { LLMAnalysisResult } from './llm';

export function calculateFinalRiskScore(
  behaviorLogs: BehaviorLog,
  llmAnalysis: LLMAnalysisResult,
  answerTime: number
): number {
  let score = 0;
  
  // LLMã®åŸºæœ¬ã‚¹ã‚³ã‚¢ï¼ˆé‡ã¿: 50%ï¼‰
  score += llmAnalysis.riskScore * 0.5;
  
  // è¡Œå‹•ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚¹ã‚³ã‚¢ï¼ˆé‡ã¿: 30%ï¼‰
  const behaviorScore = calculateBehaviorScore(behaviorLogs, answerTime);
  score += behaviorScore * 0.3;
  
  // ç¿»è¨³å¯èƒ½æ€§ã‚¹ã‚³ã‚¢ï¼ˆé‡ã¿: 20%ï¼‰
  score += llmAnalysis.translationLikelihood * 0.2;
  
  return Math.min(100, Math.max(0, Math.round(score)));
}

function calculateBehaviorScore(
  logs: BehaviorLog,
  answerTime: number
): number {
  let score = 0;
  
  // ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦åˆ‡ã‚Šæ›¿ãˆ
  if (logs.blurCount > 5) score += 30;
  else if (logs.blurCount > 3) score += 20;
  else if (logs.blurCount > 0) score += 10;
  
  // ã‚³ãƒ”ãƒ¼æ“ä½œ
  if (logs.copyCount > 2) score += 25;
  else if (logs.copyCount > 0) score += 15;
  
  // ãƒšãƒ¼ã‚¹ãƒˆæ“ä½œï¼ˆé«˜ãƒªã‚¹ã‚¯ï¼‰
  if (logs.pasteCount > 0) score += 30;
  
  // ãƒã‚¦ã‚¹åœæ­¢
  const inactiveSeconds = logs.mouseInactiveTime / 1000;
  if (inactiveSeconds > 120) score += 25;
  else if (inactiveSeconds > 60) score += 15;
  
  // ã‚¿ã‚¤ãƒ”ãƒ³ã‚°é€Ÿåº¦
  if (logs.typingSpeed > 6) score += 20; // ç•°å¸¸ã«é€Ÿã„
  else if (logs.typingSpeed < 1 && logs.keyPressCount > 50) score += 15; // ç•°å¸¸ã«é…ã„
  
  // ã‚³ãƒ”ãƒ¼ â†’ ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦åˆ‡ã‚Šæ›¿ãˆ â†’ é«˜é€Ÿè§£ç­”ã®ãƒ‘ã‚¿ãƒ¼ãƒ³
  if (
    logs.copyCount > 0 &&
    logs.blurCount > 0 &&
    answerTime < 60 &&
    logs.blurDurations.some(d => d > 3000)
  ) {
    score += 35; // éå¸¸ã«ç–‘ã‚ã—ã„
  }
  
  return Math.min(100, score);
}

export async function analyzeFraudRisk(attemptId: string): Promise<void> {
  const { prisma } = await import('./prisma');
  const { analyzeBehavior } = await import('./llm');
  
  // è§£ç­”ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
  const attempt = await prisma.testAttempt.findUnique({
    where: { id: attemptId },
    include: { question: true },
  });
  
  if (!attempt) {
    throw new Error('Attempt not found');
  }
  
  // LLMã§åˆ†æ
  const llmResult = await analyzeBehavior({
    questionText: attempt.question.questionText,
    questionDifficulty: attempt.question.difficulty,
    userAnswer: attempt.answer,
    behaviorLogs: attempt.behaviorLogs as BehaviorLog,
    answerTime: attempt.answerTime,
  });
  
  // æœ€çµ‚ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
  const finalScore = calculateFinalRiskScore(
    attempt.behaviorLogs as BehaviorLog,
    llmResult,
    attempt.answerTime
  );
  
  // DBã‚’æ›´æ–°
  await prisma.testAttempt.update({
    where: { id: attemptId },
    data: {
      riskScore: finalScore,
      llmAnalysis: llmResult as any,
      status: finalScore > 70 ? 'flagged' : 'completed',
    },
  });
}
```

---

## ğŸ’° ã‚³ã‚¹ãƒˆç®¡ç†

### ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã®è¦‹ç©ã‚‚ã‚Š

```typescript
// 1å›ã®åˆ†æã‚ãŸã‚Š
const TOKENS_PER_ANALYSIS = {
  input: {
    prompt: 500,      // ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
    question: 200,    // å•é¡Œæ–‡
    answer: 150,      // å—é¨“è€…ã®è§£ç­”
    behaviorLogs: 100, // è¡Œå‹•ãƒ­ã‚°
    total: 950
  },
  output: {
    analysis: 200     // åˆ†æçµæœ
  }
};

// GPT-5-miniæ–™é‡‘ï¼ˆæƒ³å®šï¼‰
const COST_PER_1M_TOKENS = {
  input: 0.15,  // $0.15 / 1M tokens
  output: 0.6,  // $0.6 / 1M tokens
};

// 1å›ã‚ãŸã‚Šã®ã‚³ã‚¹ãƒˆ
const costPerAnalysis = 
  (TOKENS_PER_ANALYSIS.input.total / 1_000_000) * COST_PER_ANALYSIS.input +
  (TOKENS_PER_ANALYSIS.output.analysis / 1_000_000) * COST_PER_ANALYSIS.output;

console.log(`1å›ã‚ãŸã‚Š: $${costPerAnalysis.toFixed(6)} (ç´„${(costPerAnalysis * 150).toFixed(2)}å††)`);
// å‡ºåŠ›: 1å›ã‚ãŸã‚Š: $0.000263 (ç´„0.04å††)
```

### ã‚³ã‚¹ãƒˆå‰Šæ¸›ç­–

| æ–½ç­– | åŠ¹æœ |
|:---|:---|
| ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æœ€é©åŒ– | -20% |
| ä¸è¦ãªæƒ…å ±ã®å‰Šé™¤ | -15% |
| ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®æ´»ç”¨ | -30%ï¼ˆåŒã˜å•é¡Œã®å ´åˆï¼‰ |

---

## ğŸ”„ éåŒæœŸå‡¦ç†

LLMåˆ†æã¯æ™‚é–“ãŒã‹ã‹ã‚‹ãŸã‚ã€éåŒæœŸã§å®Ÿè¡Œã—ã¾ã™ã€‚

```typescript
// app/api/submit/route.ts

export async function POST(request: Request) {
  // ...è§£ç­”ã‚’DBã«ä¿å­˜...
  
  // LLMåˆ†æã‚’éåŒæœŸã§ãƒˆãƒªã‚¬ãƒ¼ï¼ˆå¾…ãŸãªã„ï¼‰
  analyzeFraudRisk(attempt.id).catch(error => {
    console.error('Background analysis failed:', error);
  });
  
  // ã™ãã«ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¿”ã™
  return NextResponse.json({
    success: true,
    attemptId: attempt.id,
  });
}
```

---

## ğŸ§ª ãƒ†ã‚¹ãƒˆæˆ¦ç•¥

### 1. ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆ

```typescript
// __tests__/llm.test.ts

describe('analyzeBehavior', () => {
  it('é«˜ãƒªã‚¹ã‚¯ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡ºã™ã‚‹', async () => {
    const input = {
      questionText: 'What is climate change?',
      questionDifficulty: 'medium',
      userAnswer: 'Climate change is...',
      behaviorLogs: {
        blurCount: 5,
        copyCount: 2,
        // ...
      },
      answerTime: 30,
    };
    
    const result = await analyzeBehavior(input);
    
    expect(result.riskScore).toBeGreaterThan(70);
    expect(result.suspiciousPatterns).toContain('copy_blur_fast_answer');
  });
});
```

### 2. ãƒ¢ãƒƒã‚¯å¿œç­”

é–‹ç™ºæ™‚ã¯OpenAI APIã‚’ãƒ¢ãƒƒã‚¯ã—ã¦é«˜é€ŸåŒ–ï¼š

```typescript
// lib/llm.mock.ts

export function mockAnalyzeBehavior(): LLMAnalysisResult {
  return {
    riskScore: 75,
    translationLikelihood: 80,
    reasons: ['ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ¢ãƒƒã‚¯å¿œç­”'],
    suspiciousPatterns: ['mock_pattern'],
    answerQuality: 0.8,
    recommendation: 'ãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã§ã™',
  };
}
```

---

## ğŸ“ˆ æ”¹å–„æ¡ˆï¼ˆå°†æ¥ï¼‰

| é …ç›® | å†…å®¹ |
|:---|:---|
| **ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°** | å®Ÿãƒ‡ãƒ¼ã‚¿ã§ãƒ¢ãƒ‡ãƒ«ã‚’èª¿æ•´ |
| **ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«** | è¤‡æ•°ã®LLMã®çµæœã‚’çµ±åˆ |
| **ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ—** | æ•™å¸«ã®åˆ¤æ–­ã‚’å­¦ç¿’ã«åæ˜  |
| **A/Bãƒ†ã‚¹ãƒˆ** | ç•°ãªã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®åŠ¹æœæ¸¬å®š |

---

ä»¥ä¸Šã§LLMçµ±åˆè¨­è¨ˆã®èª¬æ˜ã‚’çµ‚ã‚ã‚Šã¾ã™ã€‚

